{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1050 images belonging to 8 classes.\n",
      "Found 259 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define image dimensions\n",
    "img_height, img_width = 240, 240\n",
    "batch_size = 32\n",
    "\n",
    "# Load dataset using ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,  # Normalize pixel values to [0, 1]\n",
    "    validation_split=0.2  # Split 20% of data for validation\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    \"dataset/images\",  # Replace with the path to your dataset\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Use this for training data\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    \"dataset/images\",  # Replace with the path to your dataset\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Use this for validation data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "# Load MobileNetV2 with pre-trained weights (excluding the top classification layer)\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(img_height, img_width, 3),  # Input shape for 240x240 RGB images\n",
    "    include_top=False,  # Exclude the top classification layer\n",
    "    weights='imagenet'  # Use pre-trained weights from ImageNet\n",
    ")\n",
    "\n",
    "# Freeze the base model to prevent training its layers initially\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Global average pooling to reduce dimensions\n",
    "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "x = Dropout(0.5)(x)  # Dropout to prevent overfitting\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)  # Output layer\n",
    "\n",
    "# Combine the base model and custom layers into a new model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',  # Adam optimizer\n",
    "    loss='categorical_crossentropy',  # Loss function for multi-class classification\n",
    "    metrics=['accuracy']  # Track accuracy during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 31s 921ms/step - loss: 0.4534 - accuracy: 0.8487 - val_loss: 0.3451 - val_accuracy: 0.9141\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 26s 832ms/step - loss: 0.0303 - accuracy: 0.9902 - val_loss: 0.4610 - val_accuracy: 0.8867\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 27s 833ms/step - loss: 0.0149 - accuracy: 0.9980 - val_loss: 0.4496 - val_accuracy: 0.9180\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 27s 834ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.5391 - val_accuracy: 0.9062\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 26s 809ms/step - loss: 0.0080 - accuracy: 0.9990 - val_loss: 0.5127 - val_accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 26s 813ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4992 - val_accuracy: 0.9062\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 26s 822ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5381 - val_accuracy: 0.9102\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 26s 806ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4579 - val_accuracy: 0.9180\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 27s 845ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4766 - val_accuracy: 0.9141\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 28s 888ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.8906\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=10  # Number of epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 655ms/step - loss: 0.4520 - accuracy: 0.8919\n",
      "Validation Accuracy: 0.8919\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/28 [==============================] - 118s 4s/step - loss: 1.7504 - accuracy: 0.5582 - val_loss: 0.4355 - val_accuracy: 0.8973\n",
      "Epoch 2/5\n",
      "28/28 [==============================] - 102s 4s/step - loss: 0.3047 - accuracy: 0.9016 - val_loss: 0.4426 - val_accuracy: 0.9018\n",
      "Epoch 3/5\n",
      "28/28 [==============================] - 100s 4s/step - loss: 0.1060 - accuracy: 0.9687 - val_loss: 0.4121 - val_accuracy: 0.8973\n",
      "Epoch 4/5\n",
      "28/28 [==============================] - 100s 4s/step - loss: 0.0618 - accuracy: 0.9899 - val_loss: 0.4073 - val_accuracy: 0.8929\n",
      "Epoch 5/5\n",
      "28/28 [==============================] - 100s 4s/step - loss: 0.0577 - accuracy: 0.9866 - val_loss: 0.3913 - val_accuracy: 0.8973\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze the top layers of the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),  # Lower learning rate\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Continue training\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=5  # Additional epochs for fine-tuning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as mobilenetv2_sign_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model.save(\"Final_handSignModel.h5\")\n",
    "print(\"Model saved as mobilenetv2_sign_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
